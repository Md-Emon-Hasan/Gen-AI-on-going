{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c0aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # LLM Hallucination - Complete Guide\n",
    "# \n",
    "# ‡¶è‡¶á notebook ‡¶è ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶∂‡¶ø‡¶ñ‡¶¨‡ßã:\n",
    "# 1. Hallucination ‡¶ï‡¶ø ‡¶è‡¶¨‡¶Ç ‡¶ï‡ßá‡¶® ‡¶π‡¶Ø‡¶º\n",
    "# 2. Hallucination ‡¶è‡¶∞ types\n",
    "# 3. Hallucination detect ‡¶ï‡¶∞‡¶æ\n",
    "# 4. Hallucination reduce/prevent ‡¶ï‡¶∞‡¶æ\n",
    "# 5. Real-world solutions\n",
    "\n",
    "# %% [markdown]\n",
    "# ## What is Hallucination? ü§î\n",
    "# \n",
    "# **Hallucination** ‡¶Æ‡¶æ‡¶®‡ßá ‡¶Ø‡¶ñ‡¶® AI model ‡¶è‡¶Æ‡¶® ‡¶ï‡¶ø‡¶õ‡ßÅ generate ‡¶ï‡¶∞‡ßá ‡¶Ø‡ßá‡¶ü‡¶æ:\n",
    "# - ‚ùå Factually incorrect (‡¶≠‡ßÅ‡¶≤ ‡¶§‡¶•‡ßç‡¶Ø)\n",
    "# - ‚ùå Doesn't exist (‡¶¨‡¶æ‡¶®‡¶æ‡¶®‡ßã ‡¶§‡¶•‡ßç‡¶Ø)\n",
    "# - ‚ùå Not supported by input/context (context ‡¶è ‡¶®‡ßá‡¶á)\n",
    "# - ‚ùå Logically inconsistent (contradictory)\n",
    "# \n",
    "# ### Real-world Examples:\n",
    "# \n",
    "# 1. **Factual Hallucination:**\n",
    "#    - Query: \"When did Einstein invent the telephone?\"\n",
    "#    - AI: \"Einstein invented the telephone in 1876\"\n",
    "#    - Reality: Einstein didn't invent the telephone, it was Alexander Graham Bell\n",
    "# \n",
    "# 2. **Source Hallucination:**\n",
    "#    - Query: \"What does the article say about climate change?\"\n",
    "#    - AI: \"The article mentions a 5-degree increase by 2030\"\n",
    "#    - Reality: Article doesn't mention this specific number\n",
    "# \n",
    "# 3. **Confidence Hallucination:**\n",
    "#    - AI gives completely wrong answer but with 100% confidence\n",
    "# \n",
    "# ### ‡¶ï‡ßá‡¶® Hallucination ‡¶π‡¶Ø‡¶º?\n",
    "# \n",
    "# 1. **Training Data Issues** - ‡¶≠‡ßÅ‡¶≤ ‡¶¨‡¶æ incomplete data\n",
    "# 2. **Model Limitations** - Model ‡¶Ø‡ßá‡¶ü‡¶æ ‡¶ú‡¶æ‡¶®‡ßá ‡¶®‡¶æ ‡¶∏‡ßá‡¶ü‡¶æ guess ‡¶ï‡¶∞‡ßá\n",
    "# 3. **Ambiguous Queries** - unclear ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®\n",
    "# 4. **Context Missing** - ‡¶™‡¶∞‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶§ context ‡¶®‡¶æ ‡¶•‡¶æ‡¶ï‡¶æ\n",
    "# 5. **Over-confidence** - Model too confident in wrong answers\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Setup\n",
    "\n",
    "# %%\n",
    "# !pip install langgraph langchain-google-genai langchain-community langchain-core python-dotenv sentence-transformers scikit-learn\n",
    "\n",
    "# %%\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, List, Dict\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"models/gemini-2.5-flash\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Example 1: Detecting Factual Hallucinations\n",
    "\n",
    "# %%\n",
    "def test_hallucination_basic():\n",
    "    \"\"\"Test basic hallucination with factual questions\"\"\"\n",
    "    \n",
    "    questions = [\n",
    "        \"Who invented the telephone?\",\n",
    "        \"What is the capital of Mars?\",  # Nonsense question\n",
    "        \"When did World War II end?\",\n",
    "        \"Who is the current king of United States?\",  # US doesn't have a king\n",
    "    ]\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"TESTING FACTUAL HALLUCINATIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, question in enumerate(questions, 1):\n",
    "        print(f\"\\n{i}. Question: {question}\")\n",
    "        response = llm.invoke([HumanMessage(content=question)])\n",
    "        print(f\"   Answer: {response.content}\")\n",
    "        print(\"-\"*60)\n",
    "\n",
    "# Run test\n",
    "test_hallucination_basic()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Example 2: Source-based Hallucination Detection\n",
    "\n",
    "# %%\n",
    "# Sample document\n",
    "SAMPLE_DOCUMENT = \"\"\"\n",
    "Tesla Inc. is an American electric vehicle and clean energy company. \n",
    "The company was founded in 2003 by Martin Eberhard and Marc Tarpenning.\n",
    "Elon Musk joined as chairman in 2004 and became CEO in 2008.\n",
    "Tesla's main products include electric cars like Model S, Model 3, Model X, and Model Y.\n",
    "The company's headquarters is located in Austin, Texas.\n",
    "In 2023, Tesla delivered approximately 1.8 million vehicles worldwide.\n",
    "\"\"\"\n",
    "\n",
    "def check_source_hallucination(context: str, question: str, answer: str) -> dict:\n",
    "    \"\"\"Check if answer is grounded in the source\"\"\"\n",
    "    \n",
    "    # Method 1: Simple keyword matching\n",
    "    answer_lower = answer.lower()\n",
    "    context_lower = context.lower()\n",
    "    \n",
    "    # Extract key facts from answer\n",
    "    # For demo, we'll use a simple approach\n",
    "    \n",
    "    # Method 2: Use LLM to verify\n",
    "    verification_prompt = f\"\"\"\n",
    "    Given the following context, verify if the answer is supported by the context.\n",
    "    \n",
    "    Context: {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    Answer: {answer}\n",
    "    \n",
    "    Respond with JSON:\n",
    "    {{\n",
    "        \"is_supported\": true/false,\n",
    "        \"confidence\": 0-100,\n",
    "        \"explanation\": \"brief explanation\",\n",
    "        \"unsupported_claims\": [\"list of claims not in context\"]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    verification = llm.invoke([HumanMessage(content=verification_prompt)])\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(verification.content.strip().replace(\"```json\", \"\").replace(\"```\", \"\"))\n",
    "    except:\n",
    "        result = {\"is_supported\": False, \"confidence\": 0, \"explanation\": \"Could not parse\"}\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test\n",
    "print(\"=\"*60)\n",
    "print(\"TESTING SOURCE-BASED HALLUCINATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"question\": \"Who founded Tesla?\",\n",
    "        \"answer\": \"Tesla was founded by Martin Eberhard and Marc Tarpenning in 2003.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"When did Elon Musk join Tesla?\",\n",
    "        \"answer\": \"Elon Musk joined Tesla in 2004 as chairman.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many cars did Tesla deliver in 2023?\",\n",
    "        \"answer\": \"Tesla delivered approximately 3 million vehicles in 2023.\"  # WRONG!\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Where is Tesla's headquarters?\",\n",
    "        \"answer\": \"Tesla's headquarters is in San Francisco, California.\"  # WRONG!\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\n{i}. Question: {test_case['question']}\")\n",
    "    print(f\"   Answer: {test_case['answer']}\")\n",
    "    \n",
    "    result = check_source_hallucination(\n",
    "        SAMPLE_DOCUMENT,\n",
    "        test_case['question'],\n",
    "        test_case['answer']\n",
    "    )\n",
    "    \n",
    "    print(f\"   ‚úì Supported: {result.get('is_supported', 'Unknown')}\")\n",
    "    print(f\"   Confidence: {result.get('confidence', 0)}%\")\n",
    "    print(f\"   Explanation: {result.get('explanation', 'N/A')}\")\n",
    "    \n",
    "    if not result.get('is_supported', False):\n",
    "        print(f\"   ‚ö†Ô∏è Unsupported claims: {result.get('unsupported_claims', [])}\")\n",
    "    \n",
    "    print(\"-\"*60)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Example 3: RAG with Hallucination Detection\n",
    "\n",
    "# %%\n",
    "# Create a sample knowledge base\n",
    "knowledge_base = [\n",
    "    \"Python was created by Guido van Rossum and first released in 1991.\",\n",
    "    \"JavaScript was created by Brendan Eich in 1995 in just 10 days.\",\n",
    "    \"Java was developed by James Gosling at Sun Microsystems and released in 1995.\",\n",
    "    \"C++ was developed by Bjarne Stroustrup starting in 1979.\",\n",
    "    \"Go was designed by Robert Griesemer, Rob Pike, and Ken Thompson at Google.\",\n",
    "]\n",
    "\n",
    "# Create vector store\n",
    "docs = [Document(page_content=text) for text in knowledge_base]\n",
    "vectorstore = Chroma.from_documents(docs, embeddings)\n",
    "\n",
    "def rag_with_hallucination_check(query: str) -> dict:\n",
    "    \"\"\"RAG with built-in hallucination detection\"\"\"\n",
    "    \n",
    "    # Step 1: Retrieve relevant docs\n",
    "    retrieved_docs = vectorstore.similarity_search(query, k=2)\n",
    "    context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    print(f\"üìö Retrieved Context:\")\n",
    "    print(context)\n",
    "    print()\n",
    "    \n",
    "    # Step 2: Generate answer\n",
    "    prompt = f\"\"\"Based on the following context, answer the question.\n",
    "    If the answer is not in the context, say \"I don't have enough information.\"\n",
    "    \n",
    "    Context: {context}\n",
    "    \n",
    "    Question: {query}\n",
    "    \n",
    "    Answer:\"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    answer = response.content\n",
    "    \n",
    "    print(f\"ü§ñ Generated Answer:\")\n",
    "    print(answer)\n",
    "    print()\n",
    "    \n",
    "    # Step 3: Check for hallucination\n",
    "    if \"don't have enough information\" in answer.lower() or \"not in the context\" in answer.lower():\n",
    "        hallucination_risk = \"LOW\"\n",
    "        grounded = True\n",
    "    else:\n",
    "        # Verify answer against context\n",
    "        verification = check_source_hallucination(context, query, answer)\n",
    "        grounded = verification.get('is_supported', False)\n",
    "        hallucination_risk = \"LOW\" if grounded else \"HIGH\"\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"context\": context,\n",
    "        \"answer\": answer,\n",
    "        \"grounded\": grounded,\n",
    "        \"hallucination_risk\": hallucination_risk\n",
    "    }\n",
    "\n",
    "# Test RAG\n",
    "print(\"=\"*60)\n",
    "print(\"RAG WITH HALLUCINATION DETECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_queries = [\n",
    "    \"Who created Python?\",  # In knowledge base\n",
    "    \"When was JavaScript created?\",  # In knowledge base\n",
    "    \"What is the capital of France?\",  # NOT in knowledge base\n",
    "    \"Who invented Rust?\",  # NOT in knowledge base\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    result = rag_with_hallucination_check(query)\n",
    "    \n",
    "    print(f\"‚úì Grounded: {result['grounded']}\")\n",
    "    print(f\"‚ö†Ô∏è Hallucination Risk: {result['hallucination_risk']}\")\n",
    "    print()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Example 4: Self-Consistency Check\n",
    "\n",
    "# %%\n",
    "def self_consistency_check(question: str, num_samples: int = 3) -> dict:\n",
    "    \"\"\"Generate multiple answers and check consistency\"\"\"\n",
    "    \n",
    "    print(f\"Question: {question}\\n\")\n",
    "    \n",
    "    answers = []\n",
    "    \n",
    "    # Generate multiple responses\n",
    "    for i in range(num_samples):\n",
    "        response = llm.invoke([HumanMessage(content=question)])\n",
    "        answers.append(response.content)\n",
    "        print(f\"Answer {i+1}: {response.content}\")\n",
    "    \n",
    "    # Check consistency using LLM\n",
    "    consistency_prompt = f\"\"\"\n",
    "    Compare these {num_samples} answers to the same question and determine:\n",
    "    1. Are they consistent with each other?\n",
    "    2. What are the differences?\n",
    "    3. Which answer is most likely correct?\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Answers:\n",
    "    {chr(10).join([f\"{i+1}. {ans}\" for i, ans in enumerate(answers)])}\n",
    "    \n",
    "    Respond with JSON:\n",
    "    {{\n",
    "        \"consistent\": true/false,\n",
    "        \"confidence\": 0-100,\n",
    "        \"differences\": [\"list of differences\"],\n",
    "        \"recommended_answer\": \"the most reliable answer\",\n",
    "        \"hallucination_risk\": \"LOW/MEDIUM/HIGH\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    consistency_result = llm.invoke([HumanMessage(content=consistency_prompt)])\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(consistency_result.content.strip().replace(\"```json\", \"\").replace(\"```\", \"\"))\n",
    "    except:\n",
    "        result = {\"consistent\": False, \"confidence\": 0}\n",
    "    \n",
    "    print(f\"\\nüìä Consistency Analysis:\")\n",
    "    print(f\"   Consistent: {result.get('consistent', 'Unknown')}\")\n",
    "    print(f\"   Confidence: {result.get('confidence', 0)}%\")\n",
    "    print(f\"   Hallucination Risk: {result.get('hallucination_risk', 'Unknown')}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test self-consistency\n",
    "print(\"=\"*60)\n",
    "print(\"SELF-CONSISTENCY CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_questions = [\n",
    "    \"What is 25 * 47?\",  # Factual, should be consistent\n",
    "    \"Who was the 100th president of the United States?\",  # Nonsense, may be inconsistent\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    result = self_consistency_check(question, num_samples=3)\n",
    "    print()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Example 5: Chain-of-Thought with Verification\n",
    "\n",
    "# %%\n",
    "def chain_of_thought_with_verification(question: str) -> dict:\n",
    "    \"\"\"Use CoT and then verify the reasoning\"\"\"\n",
    "    \n",
    "    # Step 1: Get answer with Chain of Thought\n",
    "    cot_prompt = f\"\"\"\n",
    "    Answer the following question step by step. Show your reasoning.\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Think through this carefully:\n",
    "    1. What information do I need?\n",
    "    2. What do I know?\n",
    "    3. What is my reasoning?\n",
    "    4. What is my final answer?\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=cot_prompt)])\n",
    "    reasoning = response.content\n",
    "    \n",
    "    print(f\"üß† Chain of Thought Reasoning:\")\n",
    "    print(reasoning)\n",
    "    print()\n",
    "    \n",
    "    # Step 2: Verify the reasoning\n",
    "    verification_prompt = f\"\"\"\n",
    "    Verify the following reasoning and answer. Point out any logical errors,\n",
    "    unsupported claims, or potential hallucinations.\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Reasoning and Answer:\n",
    "    {reasoning}\n",
    "    \n",
    "    Provide verification in JSON:\n",
    "    {{\n",
    "        \"logical_errors\": [\"list of errors\"],\n",
    "        \"unsupported_claims\": [\"claims without evidence\"],\n",
    "        \"confidence_score\": 0-100,\n",
    "        \"hallucination_detected\": true/false,\n",
    "        \"corrected_answer\": \"if hallucination found, provide correct answer\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    verification = llm.invoke([HumanMessage(content=verification_prompt)])\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(verification.content.strip().replace(\"```json\", \"\").replace(\"```\", \"\"))\n",
    "    except:\n",
    "        result = {\"hallucination_detected\": False}\n",
    "    \n",
    "    print(f\"‚úì Verification Results:\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"reasoning\": reasoning,\n",
    "        \"verification\": result\n",
    "    }\n",
    "\n",
    "# Test CoT with verification\n",
    "print(\"=\"*60)\n",
    "print(\"CHAIN-OF-THOUGHT WITH VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_questions = [\n",
    "    \"If a train travels 120 miles in 2 hours, what is its average speed?\",\n",
    "    \"Who won the World Cup in 2050?\",  # Future event\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print('='*60)\n",
    "    result = chain_of_thought_with_verification(question)\n",
    "    print()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Example 6: Attribution-based Hallucination Detection\n",
    "\n",
    "# %%\n",
    "def attribution_check(context: str, claim: str) -> dict:\n",
    "    \"\"\"Check if a specific claim can be attributed to the context\"\"\"\n",
    "    \n",
    "    # Use embeddings to check similarity\n",
    "    context_embedding = embeddings.embed_query(context)\n",
    "    claim_embedding = embeddings.embed_query(claim)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity(\n",
    "        [context_embedding],\n",
    "        [claim_embedding]\n",
    "    )[0][0]\n",
    "    \n",
    "    # Use LLM for detailed attribution\n",
    "    attribution_prompt = f\"\"\"\n",
    "    Context: {context}\n",
    "    \n",
    "    Claim: {claim}\n",
    "    \n",
    "    Can this claim be directly attributed to the context?\n",
    "    If yes, quote the relevant part.\n",
    "    If no, explain why.\n",
    "    \n",
    "    Respond with JSON:\n",
    "    {{\n",
    "        \"attributed\": true/false,\n",
    "        \"confidence\": 0-100,\n",
    "        \"supporting_quote\": \"exact quote if found, else null\",\n",
    "        \"explanation\": \"brief explanation\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=attribution_prompt)])\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(response.content.strip().replace(\"```json\", \"\").replace(\"```\", \"\"))\n",
    "    except:\n",
    "        result = {\"attributed\": False, \"confidence\": 0}\n",
    "    \n",
    "    result['embedding_similarity'] = float(similarity)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test attribution\n",
    "print(\"=\"*60)\n",
    "print(\"ATTRIBUTION-BASED HALLUCINATION DETECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "context = \"\"\"\n",
    "Apple Inc. announced its Q4 2023 earnings today. \n",
    "The company reported revenue of $89.5 billion, up 1% year over year.\n",
    "iPhone sales contributed $43.8 billion to the revenue.\n",
    "CEO Tim Cook stated that the company is excited about the Vision Pro launch.\n",
    "\"\"\"\n",
    "\n",
    "claims = [\n",
    "    \"Apple's Q4 2023 revenue was $89.5 billion\",  # TRUE\n",
    "    \"iPhone sales were $43.8 billion\",  # TRUE\n",
    "    \"Apple's revenue decreased by 5% year over year\",  # FALSE\n",
    "    \"Apple announced a new MacBook Pro\",  # NOT MENTIONED\n",
    "]\n",
    "\n",
    "for claim in claims:\n",
    "    print(f\"\\nClaim: {claim}\")\n",
    "    result = attribution_check(context, claim)\n",
    "    \n",
    "    print(f\"  ‚úì Attributed: {result['attributed']}\")\n",
    "    print(f\"  Confidence: {result['confidence']}%\")\n",
    "    print(f\"  Embedding Similarity: {result['embedding_similarity']:.3f}\")\n",
    "    \n",
    "    if result.get('supporting_quote'):\n",
    "        print(f\"  Quote: \\\"{result['supporting_quote']}\\\"\")\n",
    "    else:\n",
    "        print(f\"  Explanation: {result['explanation']}\")\n",
    "    \n",
    "    print(\"-\"*60)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Example 7: Confidence Calibration\n",
    "\n",
    "# %%\n",
    "def confidence_calibration(question: str) -> dict:\n",
    "    \"\"\"Ask model to provide confidence score with answer\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Answer the following question and provide a confidence score (0-100).\n",
    "    If you're not sure, be honest about it.\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Respond with JSON:\n",
    "    {{\n",
    "        \"answer\": \"your answer\",\n",
    "        \"confidence\": 0-100,\n",
    "        \"reasoning\": \"why this confidence level\",\n",
    "        \"sources_of_uncertainty\": [\"what makes you uncertain\"]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    try:\n",
    "        result = json.loads(response.content.strip().replace(\"```json\", \"\").replace(\"```\", \"\"))\n",
    "    except:\n",
    "        result = {\"answer\": response.content, \"confidence\": 50}\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test confidence calibration\n",
    "print(\"=\"*60)\n",
    "print(\"CONFIDENCE CALIBRATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_questions = [\n",
    "    \"What is the capital of France?\",  # Easy, high confidence\n",
    "    \"What is the population of Iceland?\",  # Harder, medium confidence\n",
    "    \"What is the GDP of Bhutan?\",  # Hard, low confidence\n",
    "    \"Who will win the next World Cup?\",  # Impossible, should be very low\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    result = confidence_calibration(question)\n",
    "    \n",
    "    print(f\"  Answer: {result['answer']}\")\n",
    "    print(f\"  Confidence: {result['confidence']}%\")\n",
    "    print(f\"  Reasoning: {result.get('reasoning', 'N/A')}\")\n",
    "    \n",
    "    if result['confidence'] < 50:\n",
    "        print(f\"  ‚ö†Ô∏è LOW CONFIDENCE - High hallucination risk!\")\n",
    "    \n",
    "    print(\"-\"*60)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Best Practices to Reduce Hallucinations\n",
    "# \n",
    "# ### 1Ô∏è‚É£ Prompt Engineering\n",
    "# ```python\n",
    "# # ‚ùå Bad Prompt\n",
    "# \"Tell me about XYZ\"\n",
    "# \n",
    "# # ‚úÖ Good Prompt\n",
    "# \"Based on the provided context, tell me about XYZ. \n",
    "#  If the information is not in the context, say 'I don't know'.\"\n",
    "# ```\n",
    "# \n",
    "# ### 2Ô∏è‚É£ RAG (Retrieval-Augmented Generation)\n",
    "# - Always provide context\n",
    "# - Use vector databases\n",
    "# - Verify answers against sources\n",
    "# \n",
    "# ### 3Ô∏è‚É£ Self-Consistency\n",
    "# - Generate multiple answers\n",
    "# - Check for consistency\n",
    "# - Flag inconsistencies\n",
    "# \n",
    "# ### 4Ô∏è‚É£ Chain-of-Thought\n",
    "# - Ask for step-by-step reasoning\n",
    "# - Easier to spot logical errors\n",
    "# - Verify each step\n",
    "# \n",
    "# ### 5Ô∏è‚É£ Attribution\n",
    "# - Require citations\n",
    "# - Check if claims match sources\n",
    "# - Use embedding similarity\n",
    "# \n",
    "# ### 6Ô∏è‚É£ Confidence Scores\n",
    "# - Ask model for confidence\n",
    "# - Flag low-confidence answers\n",
    "# - Human review for uncertain answers\n",
    "# \n",
    "# ### 7Ô∏è‚É£ Human-in-the-Loop\n",
    "# - Critical decisions need human verification\n",
    "# - Use HITL for high-stakes applications\n",
    "# \n",
    "# ### 8Ô∏è‚É£ Post-Processing\n",
    "# - Verify facts against knowledge base\n",
    "# - Use fact-checking APIs\n",
    "# - Cross-reference multiple sources\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Complete Anti-Hallucination System\n",
    "\n",
    "# %%\n",
    "class AntiHallucinationSystem:\n",
    "    \"\"\"Complete system to detect and prevent hallucinations\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, embeddings, knowledge_base=None):\n",
    "        self.llm = llm\n",
    "        self.embeddings = embeddings\n",
    "        self.knowledge_base = knowledge_base\n",
    "        \n",
    "    def generate_with_checks(self, query: str, context: str = None) -> dict:\n",
    "        \"\"\"Generate answer with multiple hallucination checks\"\"\"\n",
    "        \n",
    "        results = {\n",
    "            \"query\": query,\n",
    "            \"checks_performed\": [],\n",
    "            \"warnings\": [],\n",
    "            \"final_answer\": None,\n",
    "            \"confidence\": 0,\n",
    "            \"safe_to_use\": False\n",
    "        }\n",
    "        \n",
    "        # Check 1: Generate answer with context\n",
    "        if context:\n",
    "            prompt = f\"\"\"Based on this context, answer the question.\n",
    "            If not in context, say \"I don't have enough information.\"\n",
    "            \n",
    "            Context: {context}\n",
    "            Question: {query}\n",
    "            \"\"\"\n",
    "        else:\n",
    "            prompt = query\n",
    "        \n",
    "        response = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "        answer = response.content\n",
    "        \n",
    "        results['initial_answer'] = answer\n",
    "        results['checks_performed'].append(\"‚úì Initial generation\")\n",
    "        \n",
    "        # Check 2: Self-consistency\n",
    "        answers = [answer]\n",
    "        for _ in range(2):\n",
    "            resp = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "            answers.append(resp.content)\n",
    "        \n",
    "        # Simple consistency check\n",
    "        all_similar = len(set(answers)) <= 2  # Allow minor variations\n",
    "        results['checks_performed'].append(f\"‚úì Self-consistency: {'PASS' if all_similar else 'FAIL'}\")\n",
    "        \n",
    "        if not all_similar:\n",
    "            results['warnings'].append(\"‚ö†Ô∏è Inconsistent answers detected\")\n",
    "        \n",
    "        # Check 3: Source attribution (if context provided)\n",
    "        if context:\n",
    "            attribution = attribution_check(context, answer)\n",
    "            results['checks_performed'].append(f\"‚úì Attribution: {'PASS' if attribution['attributed'] else 'FAIL'}\")\n",
    "            \n",
    "            if not attribution['attributed']:\n",
    "                results['warnings'].append(\"‚ö†Ô∏è Answer not well-supported by context\")\n",
    "        \n",
    "        # Check 4: Confidence calibration\n",
    "        conf_result = confidence_calibration(query)\n",
    "        confidence = conf_result.get('confidence', 50)\n",
    "        results['confidence'] = confidence\n",
    "        results['checks_performed'].append(f\"‚úì Confidence: {confidence}%\")\n",
    "        \n",
    "        if confidence < 60:\n",
    "            results['warnings'].append(f\"‚ö†Ô∏è Low confidence ({confidence}%)\")\n",
    "        \n",
    "        # Final decision\n",
    "        if len(results['warnings']) == 0 and confidence >= 70:\n",
    "            results['safe_to_use'] = True\n",
    "            results['final_answer'] = answer\n",
    "        elif len(results['warnings']) <= 1 and confidence >= 60:\n",
    "            results['safe_to_use'] = True\n",
    "            results['final_answer'] = f\"‚ö†Ô∏è {answer}\\n(Note: Answer has medium confidence)\"\n",
    "        else:\n",
    "            results['safe_to_use'] = False\n",
    "            results['final_answer'] = \"I cannot provide a reliable answer. Please verify with other sources.\"\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test the complete system\n",
    "print(\"=\"*60)\n",
    "print(\"COMPLETE ANTI-HALLUCINATION SYSTEM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "system = AntiHallucinationSystem(llm, embeddings)\n",
    "\n",
    "context = \"\"\"\n",
    "The Moon is Earth's only natural satellite. It orbits Earth at an average\n",
    "distance of 384,400 km. The Moon's diameter is 3,474 km, about one-quarter\n",
    "of Earth's diameter. It takes 27.3 days to orbit Earth.\n",
    "\"\"\"\n",
    "\n",
    "test_cases = [\n",
    "    (\"What is the Moon's diameter?\", context),\n",
    "    (\"How long does it take the Moon to orbit Earth?\", context),\n",
    "    (\"What is the temperature on the Moon?\", context),  # Not in context\n",
    "]\n",
    "\n",
    "for query, ctx in test_cases:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    result = system.generate_with_checks(query, ctx)\n",
    "    \n",
    "    print(\"\\nChecks Performed:\")\n",
    "    for check in result['checks_performed']:\n",
    "        print(f\"  {check}\")\n",
    "    \n",
    "    if result['warnings']:\n",
    "        print(\"\\n‚ö†Ô∏è Warnings:\")\n",
    "        for warning in result['warnings']:\n",
    "            print(f\"  {warning}\")\n",
    "    \n",
    "    print(f\"\\nConfidence: {result['confidence']}%\")\n",
    "    print(f\"Safe to use: {result['safe_to_use']}\")\n",
    "    print(f\"\\nFinal Answer: {result['final_answer']}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Summary & Takeaways\n",
    "# \n",
    "# ### üéì What We Learned:\n",
    "# \n",
    "# 1. **Types of Hallucinations:**\n",
    "#    - Factual hallucinations\n",
    "#    - Source hallucinations\n",
    "#    - Confidence hallucinations\n",
    "# \n",
    "# 2. **Detection Methods:**\n",
    "#    - Source verification\n",
    "#    - Self-consistency checks\n",
    "#    - Attribution checking\n",
    "#    - Confidence calibration\n",
    "#    - Chain-of-thought verification\n",
    "# \n",
    "# 3. **Prevention Strategies:**\n",
    "#    - Use RAG with proper context\n",
    "#    - Implement multiple verification layers\n",
    "#    - Request confidence scores\n",
    "#    - Use self-consistency\n",
    "#    - Employ human-in-the-loop\n",
    "# \n",
    "# ### üí° Key Principles:\n",
    "# \n",
    "# ‚úÖ **Always provide context** - Don't let the model guess\n",
    "# ‚úÖ **Verify against sources** - Check if answer is grounded\n",
    "# ‚úÖ **Use multiple checks** - Combine different methods\n",
    "# ‚úÖ **Request confidence** - Know when to trust the answer\n",
    "# ‚úÖ **Human review for critical** - Don't automate everything\n",
    "# \n",
    "# ### üö´ Never Do:\n",
    "# \n",
    "# ‚ùå Trust LLM output blindly for critical applications\n",
    "# ‚ùå Use LLMs without context for factual questions\n",
    "# ‚ùå Ignore low confidence scores\n",
    "# ‚ùå Skip verification steps to save time\n",
    "# \n",
    "# ### üéØ When to Use What:\n",
    "# \n",
    "# | Use Case | Best Method |\n",
    "# |----------|-------------|\n",
    "# | Factual Q&A | RAG + Attribution |\n",
    "# | Creative Writing | Self-Consistency |\n",
    "# | Critical Decisions | Full System + HITL |\n",
    "# | Simple Queries | Confidence Calibration |\n",
    "# | Research | Multiple Sources + Verification |\n",
    "\n",
    "# %%\n",
    "print(\"‚úÖ Hallucination Tutorial Complete!\")\n",
    "print(\"\\nüìö You now know:\")\n",
    "print(\"  - What hallucinations are and why they occur\")\n",
    "print(\"  - How to detect different types of hallucinations\")\n",
    "print(\"  - Multiple methods to reduce hallucinations\")\n",
    "print(\"  - How to build a complete anti-hallucination system\")\n",
    "print(\"\\nüéâ You're ready to build reliable AI systems!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
